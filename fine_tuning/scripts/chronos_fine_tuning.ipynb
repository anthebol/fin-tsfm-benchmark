{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84006,"status":"ok","timestamp":1741061550511,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"hIR0ls56I08x","outputId":"00c3c11f-fea6-4b3c-ca0c-5db3ceba90de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git (from chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Cloning https://github.com/amazon-science/chronos-forecasting.git to /tmp/pip-install-izn0thej/chronos-forecasting_55b3a4e4726e43828a94c175d2fd03c0\n","  Running command git clone --filter=blob:none --quiet https://github.com/amazon-science/chronos-forecasting.git /tmp/pip-install-izn0thej/chronos-forecasting_55b3a4e4726e43828a94c175d2fd03c0\n","  Resolved https://github.com/amazon-science/chronos-forecasting.git to commit 94e20ea7e510ac4d665492b8bed8836a5143f16e\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate<1,>=0.32 (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.5.1+cu124)\n","Requirement already satisfied: transformers<5,>=4.48 in /usr/local/lib/python3.11/dist-packages (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (4.48.3)\n","Collecting datasets~=2.18 (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Collecting gluonts~=0.15 (from gluonts[pro]~=0.15; extra == \"training\"->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading gluonts-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.4.2)\n","Requirement already satisfied: numpy~=1.21 in /usr/local/lib/python3.11/dist-packages (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.6.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.18.0)\n","Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.15.1)\n","Collecting typer-config (from chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading typer_config-1.4.2-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<1,>=0.32->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<1,>=0.32->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<1,>=0.32->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (6.0.2)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<1,>=0.32->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.28.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<1,>=0.32->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.17.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (4.67.1)\n","Collecting xxhash (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.11.13)\n","Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts~=0.15->gluonts[pro]~=0.15; extra == \"training\"->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.10.6)\n","Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.11/dist-packages (from gluonts~=0.15->gluonts[pro]~=0.15; extra == \"training\"->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.12.1)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gluonts~=0.15->gluonts[pro]~=0.15; extra == \"training\"->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (4.12.2)\n","Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from gluonts[pro]~=0.15; extra == \"training\"->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.10.15)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.1.5)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.48->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.48->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.21.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.5.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.70.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (4.25.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.1.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (13.9.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (1.18.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2025.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts~=0.15->gluonts[pro]~=0.15; extra == \"training\"->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts~=0.15->gluonts[pro]~=0.15; extra == \"training\"->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2025.1.31)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (3.0.2)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","Collecting multiprocess (from datasets~=2.18->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->chronos-forecasting@ git+https://github.com/amazon-science/chronos-forecasting.git->chronos-forecasting[training]@ git+https://github.com/amazon-science/chronos-forecasting.git) (0.1.2)\n","Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gluonts-0.16.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/67/42/f4f60238e8194a3106d06a058d494b18e006c10bb2b915655bd9f6ea4cb1/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n","\u001b[0mDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typer_config-1.4.2-py3-none-any.whl (11 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: chronos-forecasting\n","  Building wheel for chronos-forecasting (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for chronos-forecasting: filename=chronos_forecasting-1.5.0-py3-none-any.whl size=29408 sha256=b17f84325bd5ed0f4757227997214e2c0d3b4452ab26432d87109511a2d61873\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-gewnfgq0/wheels/ba/7f/47/c8e535215a6b02669af6db36392beef76752951c59bf8b5e74\n","Successfully built chronos-forecasting\n","Installing collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, gluonts, typer-config, datasets, accelerate, chronos-forecasting\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.3.0\n","    Uninstalling accelerate-1.3.0:\n","      Successfully uninstalled accelerate-1.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.34.2 chronos-forecasting-1.5.0 datasets-2.21.0 dill-0.3.8 fsspec-2024.6.1 gluonts-0.16.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 typer-config-1.4.2 xxhash-3.5.0\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (0.34.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n","Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.28.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n"]}],"source":["!pip install \"chronos-forecasting[training] @ git+https://github.com/amazon-science/chronos-forecasting.git\"\n","!pip install peft transformers accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28771,"status":"ok","timestamp":1741061608940,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"uzCRN567JxCq","outputId":"07d76e91-56ab-401c-fcbc-37a2cd601d0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15433,"status":"ok","timestamp":1741061696492,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"Wta8ES74JTyz"},"outputs":[],"source":["import yfinance as yf\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from gluonts.dataset.arrow import ArrowWriter\n","from chronos import ChronosPipeline\n","from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n","import torch\n","from tqdm.auto import tqdm\n","import time\n","import yaml\n","from datetime import datetime"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1741062601002,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"zZj2cxZtJfLt","outputId":"7c7310b9-d5cc-4230-a8ed-6a5eca96ca24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fetching S&P 500 data...\n","Added SP500 with 24366 entries\n","Processed SP500: 24366 entries from 1928-01-03 to 2024-12-31\n"]}],"source":["import yfinance as yf\n","import pandas as pd\n","\n","def fetch_financial_data():\n","    data_dict = {}\n","\n","    def download_close(symbol, start_date='1928-01-01', end_date='2025-01-02'):\n","        # Download the data\n","        df = yf.download(symbol, start=start_date, end=end_date, interval=\"1d\", progress=False)\n","\n","        if df.empty:\n","            return None\n","\n","        # -- 1. Flatten multi-level columns if necessary --\n","        # Sometimes yfinance returns multi-level columns, especially if there's a grouping.\n","        if isinstance(df.columns, pd.MultiIndex):\n","            # Flatten the columns into strings like 'Close' or 'Close_Symbol'\n","            df.columns = ['_'.join(tuple(str(level) for level in col if level))\n","                          for col in df.columns]\n","            # After flattening, the 'Close' column might appear as 'Close' or 'Close_^GSPC', etc.\n","            # We'll look for any flattened column name starting with 'Close'.\n","            potential_close_cols = [c for c in df.columns if c.lower().startswith('close')]\n","            if len(potential_close_cols) == 1:\n","                # Found a unique column for 'Close'\n","                close_col = potential_close_cols[0]\n","            else:\n","                print(f\"WARNING: Multiple or zero 'Close' columns found for {symbol}: {potential_close_cols}\")\n","                return None\n","        else:\n","            # Single-level columns, just look for 'Close'\n","            if 'Close' not in df.columns:\n","                print(f\"WARNING: No 'Close' column found for {symbol}\")\n","                return None\n","            close_col = 'Close'\n","\n","        # -- 2. Reset index to be sure 'Date' is a column, then re-set it as a DatetimeIndex --\n","        df = df.reset_index(drop=False)\n","        if 'Date' in df.columns:\n","            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n","            df = df.set_index('Date')\n","        else:\n","            # If there's no 'Date' column, we can't proceed\n","            print(f\"WARNING: No 'Date' column available for {symbol}.\")\n","            return None\n","\n","        # -- 3. Extract the 'Close' column as a real Series (1-D) --\n","        # Using `.squeeze()` if it's 1-D ensures it's truly a Series.\n","        close_series = df[[close_col]].squeeze(axis=1)\n","        # At this point, close_series should be a Pandas Series indexed by Date.\n","\n","        # If for some reason it’s not a Series:\n","        if not isinstance(close_series, pd.Series):\n","            print(f\"WARNING: {symbol} 'Close' extraction did not return a Series.\")\n","            return None\n","\n","        # Return the close prices\n","        return close_series\n","\n","    # =====================\n","    # 1) S&P 500\n","    # =====================\n","    print(\"Fetching S&P 500 data...\")\n","    try:\n","        sp500_close = download_close('^GSPC', start_date='1928-01-01', end_date='2025-01-02')\n","        if sp500_close is not None:\n","            data_dict['SP500'] = sp500_close\n","            print(f\"Added SP500 with {len(sp500_close)} entries\")\n","    except Exception as e:\n","        print(f\"Error fetching S&P 500: {e}\")\n","\n","    # # =====================\n","    # # 2) Forex\n","    # # =====================\n","    # print(\"\\nFetching Forex data...\")\n","    # forex_pairs = {\n","    #     'EUR=X': 'EURUSD',\n","    #     'GBP=X': 'GBPUSD',\n","    #     'JPY=X': 'JPYUSD',\n","    #     'AUD=X': 'AUDUSD',\n","    #     'CAD=X': 'CADUSD'\n","    # }\n","    # for symbol, name in forex_pairs.items():\n","    #     try:\n","    #         fx_close = download_close(symbol)\n","    #         if fx_close is not None:\n","    #             data_dict[name] = fx_close\n","    #             print(f\"Added {name} with {len(fx_close)} entries\")\n","    #     except Exception as e:\n","    #         print(f\"Failed to fetch {name}: {e}\")\n","\n","    # # =====================\n","    # # 3) Commodities\n","    # # =====================\n","    # print(\"\\nFetching Commodities data...\")\n","    # commodities = {\n","    #     'GC=F': 'GOLD',\n","    #     'SI=F': 'SILVER',\n","    #     'CL=F': 'CRUDE_OIL',\n","    #     'NG=F': 'NAT_GAS',\n","    #     'ZC=F': 'CORN',\n","    #     'ZW=F': 'WHEAT',\n","    #     'HG=F': 'COPPER'\n","    # }\n","    # for symbol, name in commodities.items():\n","    #     try:\n","    #         comm_close = download_close(symbol)\n","    #         if comm_close is not None:\n","    #             data_dict[name] = comm_close\n","    #             print(f\"Added {name} with {len(comm_close)} entries\")\n","    #     except Exception as e:\n","    #         print(f\"Failed to fetch {name}: {e}\")\n","\n","    # # =====================\n","    # # 4) Crypto\n","    # # =====================\n","    # print(\"\\nFetching Crypto data...\")\n","    # cryptos = {\n","    #     'BTC-USD': ('BTC', '2015-01-01'),\n","    #     'ETH-USD': ('ETH', '2017-01-01'),\n","    #     'BNB-USD': ('BNB', '2017-01-01'),\n","    #     'XRP-USD': ('XRP', '2017-01-01'),\n","    #     'SOL-USD': ('SOL', '2020-01-01')\n","    # }\n","    # for symbol, (name, start) in cryptos.items():\n","    #     try:\n","    #         crypto_close = download_close(symbol, start_date=start)\n","    #         if crypto_close is not None:\n","    #             data_dict[name] = crypto_close\n","    #             print(f\"Added {name} with {len(crypto_close)} entries\")\n","    #     except Exception as e:\n","    #         print(f\"Failed to fetch {name}: {e}\")\n","\n","    # =====================\n","    # Verify we got any data\n","    # =====================\n","    if not data_dict:\n","        raise ValueError(\"No data was successfully collected.\")\n","\n","    # =====================x\n","    # Process each series\n","    # =====================\n","    processed_series = []\n","\n","    for name, series in data_dict.items():\n","        # Double-check it's really a Series\n","        if not isinstance(series, pd.Series):\n","            print(f\"WARNING: '{name}' is not a Series, skipping.\")\n","            continue\n","\n","        # Convert to numeric (coerce any non-numeric to NaN)\n","        clean_series = pd.to_numeric(series, errors='coerce')\n","\n","        # Forward-fill, then back-fill, then drop any leftover NaN\n","        clean_series = clean_series.ffill().bfill().dropna()\n","\n","        if len(clean_series) > 0:\n","            clean_series.name = name\n","            processed_series.append(clean_series)\n","            print(f\"Processed {name}: {len(clean_series)} entries \"\n","                  f\"from {clean_series.index[0].strftime('%Y-%m-%d')} \"\n","                  f\"to {clean_series.index[-1].strftime('%Y-%m-%d')}\")\n","\n","    return processed_series\n","\n","series_list = fetch_financial_data()"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1741062614536,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"aFwF3R2_awKS"},"outputs":[],"source":["def split_time_series(series, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n","    \"\"\"\n","    Splits a time series into train, validation, and test sets while preserving time order.\n","    \"\"\"\n","    assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1.\"\n","\n","    n = len(series)\n","    train_end = int(n * train_ratio)\n","    val_end = int(n * (train_ratio + val_ratio))\n","\n","    train_data = series.iloc[:train_end]\n","    val_data = series.iloc[train_end:val_end]\n","    test_data = series.iloc[val_end:]\n","\n","    return train_data, val_data, test_data"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1741062644756,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"VD4FTVbRLSJ_","outputId":"c4aeba8e-7c54-4496-94b8-6132ccfe4620"},"outputs":[{"data":{"text/plain":["[Date\n"," 1928-01-03      17.760000\n"," 1928-01-04      17.719999\n"," 1928-01-05      17.549999\n"," 1928-01-06      17.660000\n"," 1928-01-09      17.500000\n","                  ...     \n"," 2024-12-24    6040.040039\n"," 2024-12-26    6037.589844\n"," 2024-12-27    5970.839844\n"," 2024-12-30    5906.939941\n"," 2024-12-31    5881.629883\n"," Name: SP500, Length: 24366, dtype: float64]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["series_list"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1741062647345,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"UCNaG2FVa44C","outputId":"d958e0ad-def5-40f5-994e-55c87e088987"},"outputs":[{"name":"stdout","output_type":"stream","text":["Splitted SP500 -> Train: 19492, Val: 2437, Test: 2437\n"]}],"source":["# Apply split for each series in series_list\n","train_series = []\n","val_series = []\n","test_series = []\n","\n","for series in series_list:\n","    train_data, val_data, test_data = split_time_series(series)\n","    train_series.append(train_data)\n","    val_series.append(val_data)\n","    test_series.append(test_data)\n","\n","    print(f\"Splitted {series.name} -> Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1741062010579,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"zuCtzCR5Xuf8","outputId":"8161e95f-7bcb-4411-ab48-9ad27a9d48e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Date\n","1928-01-03   NaN\n","1928-01-04   NaN\n","1928-01-05   NaN\n","1928-01-06   NaN\n","1928-01-09   NaN\n","Name: SP500, dtype: float64\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-17-5f05f605d91c>:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  returns_clipped = returns_clipped.fillna(method=\"ffill\")\n"]}],"source":["# Ensure the first element of series_list is used correctly\n","returns_clipped = series_list[0].clip(lower=-0.1, upper=0.1)\n","\n","# Handle NaN values before min-max scaling\n","returns_clipped = returns_clipped.fillna(method=\"ffill\")\n","\n","# Compute min-max values with NaN handling\n","min_val = returns_clipped.min(skipna=True)\n","max_val = returns_clipped.max(skipna=True)\n","\n","\n","# Ensure normalization only occurs if min/max are valid\n","if pd.isna(min_val) or pd.isna(max_val):\n","    print(\"Warning: Min/Max values are NaN, check input data!\")\n","else:\n","    normalized_series = (returns_clipped - min_val) / (max_val - min_val)\n","\n","print(normalized_series.head())  # Verify results"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1741062062449,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"fMNdc1GhYrc1","outputId":"08892821-f12b-4d6c-b02f-eb7051c157fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Min Value: 0.1, Max Value: 0.1\n","Date\n","1928-01-03    0.1\n","1928-01-04    0.1\n","1928-01-05    0.1\n","1928-01-06    0.1\n","1928-01-09    0.1\n","Name: SP500, dtype: float64\n"]}],"source":["print(returns_clipped.isna().sum())  # Count NaNs\n","print(f\"Min Value: {min_val}, Max Value: {max_val}\")  # Check min/max values\n","print(returns_clipped.head())  # Preview first few values"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1741061847826,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"jYsgpf4pX3Vz","outputId":"91d17cd9-783c-468d-bc45-8b2a1ceded03"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SP500</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1928-01-03</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1928-01-04</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1928-01-05</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1928-01-06</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1928-01-09</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-23</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-27</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-28</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-29</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-30</th>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23864 rows × 1 columns</p>\n","</div><br><label><b>dtype:</b> float64</label>"],"text/plain":["Date\n","1928-01-03   NaN\n","1928-01-04   NaN\n","1928-01-05   NaN\n","1928-01-06   NaN\n","1928-01-09   NaN\n","              ..\n","2022-12-23   NaN\n","2022-12-27   NaN\n","2022-12-28   NaN\n","2022-12-29   NaN\n","2022-12-30   NaN\n","Name: SP500, Length: 23864, dtype: float64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["normalized_series"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1741061746096,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"OheI6bf-_myK"},"outputs":[],"source":["def preprocess_data(series):\n","    \"\"\"\n","    Apply simplified preprocessing steps:\n","    1. Convert to returns (percent changes)\n","    2. Clip extreme values\n","    3. Normalize data\n","    \"\"\"\n","    # Ensure we're working with a Series\n","    if not isinstance(series, pd.Series):\n","        print(\"Warning: Input is not a Series. Converting...\")\n","        series = pd.Series(series.values.flatten(), index=series.index, name='SP500')\n","\n","    # Convert to returns (percent changes) as per paper recommendation\n","    returns = series\n","\n","    # Clip extreme values (outliers)\n","    returns_clipped = returns.clip(lower=-0.1, upper=0.1)\n","\n","    # Min-max scaling for normalization\n","    min_val = returns_clipped.min()\n","    max_val = returns_clipped.max()\n","    normalized_returns = (returns_clipped - min_val) / (max_val - min_val)\n","\n","    # Preserve the name of the original series\n","    try:\n","        normalized_returns.name = series.name\n","    except:\n","        normalized_returns.name = 'SP500'\n","\n","    return normalized_returns"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1741061750003,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"qfdiE7Rd_n2N"},"outputs":[],"source":["processed_series = [preprocess_data(series) for series in series_list]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1741061751582,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"B_HBUPtl_tCQ","outputId":"a0ba6431-0681-4451-941a-07f9f621cd1f"},"outputs":[{"data":{"text/plain":["[Date\n"," 1928-01-03   NaN\n"," 1928-01-04   NaN\n"," 1928-01-05   NaN\n"," 1928-01-06   NaN\n"," 1928-01-09   NaN\n","               ..\n"," 2022-12-23   NaN\n"," 2022-12-27   NaN\n"," 2022-12-28   NaN\n"," 2022-12-29   NaN\n"," 2022-12-30   NaN\n"," Name: SP500, Length: 23864, dtype: float64]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["processed_series"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1741062158070,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"_dpwxvPyZCX6","outputId":"79bca463-3892-42ff-aad7-a725aa53ec17"},"outputs":[{"data":{"text/plain":["[Date\n"," 1928-01-03      17.760000\n"," 1928-01-04      17.719999\n"," 1928-01-05      17.549999\n"," 1928-01-06      17.660000\n"," 1928-01-09      17.500000\n","                  ...     \n"," 2022-12-23    3844.820068\n"," 2022-12-27    3829.250000\n"," 2022-12-28    3783.219971\n"," 2022-12-29    3849.280029\n"," 2022-12-30    3839.500000\n"," Name: SP500, Length: 23864, dtype: float64]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["series_list"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1741062164588,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"WDN113KBZES7","outputId":"f0ecc2d5-f905-42c5-a376-ceb1335eb1b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Date\n","1928-01-03    0.002788\n","1928-01-04    0.002780\n","1928-01-05    0.002744\n","1928-01-06    0.002767\n","1928-01-09    0.002734\n","Name: SP500, dtype: float64\n"]}],"source":["# Extract raw price series\n","raw_prices = series_list[0]  # Since it's a Series\n","\n","# Compute min and max values\n","min_val = raw_prices.min()\n","max_val = raw_prices.max()\n","\n","# Ensure min and max are not equal to avoid division by zero\n","if min_val == max_val:\n","    print(\"Warning: All values are the same. Normalization is not possible.\")\n","    normalized_series = raw_prices  # Keep as is\n","else:\n","    normalized_series = (raw_prices - min_val) / (max_val - min_val)\n","\n","# Check results\n","print(normalized_series.head())"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1741062818070,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"-Ix495nibjBD","outputId":"a8405198-af02-40e1-e528-2556bf8bdaa5"},"outputs":[{"data":{"text/plain":["[Date\n"," 1928-01-03      17.760000\n"," 1928-01-04      17.719999\n"," 1928-01-05      17.549999\n"," 1928-01-06      17.660000\n"," 1928-01-09      17.500000\n","                  ...     \n"," 2005-08-12    1230.390015\n"," 2005-08-15    1233.869995\n"," 2005-08-16    1219.339966\n"," 2005-08-17    1220.239990\n"," 2005-08-18    1219.020020\n"," Name: SP500, Length: 19492, dtype: float64]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["train_series"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1741062850348,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"13lbrFzubK4U","outputId":"b1d7a9fc-f025-48c9-ae46-101bd6942268"},"outputs":[{"name":"stdout","output_type":"stream","text":["Date\n","1928-01-03    0.008772\n","1928-01-04    0.008746\n","1928-01-05    0.008634\n","1928-01-06    0.008706\n","1928-01-09    0.008601\n","Name: SP500, dtype: float64\n"]}],"source":["# Extract raw price series\n","raw_prices_train = train_series[0]  # Since it's a Series\n","\n","# Compute min and max values\n","min_val_train = raw_prices_train.min()\n","max_val_train = raw_prices_train.max()\n","\n","train_normalized_series = (raw_prices_train - min_val_train) / (max_val_train - min_val_train)\n","\n","# Check results\n","print(train_normalized_series.head())"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1741062927138,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"8EZr7tgUbt4a","outputId":"c7657dd1-73c7-4e3e-fa18-8c98161a63e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Date\n","2005-08-19    0.376905\n","2005-08-22    0.378306\n","2005-08-23    0.375434\n","2005-08-24    0.369883\n","2005-08-25    0.371812\n","Name: SP500, dtype: float64\n"]}],"source":["# Extract raw price series\n","raw_prices_val = val_series[0]  # Since it's a Series\n","\n","# Compute min and max values\n","min_val_val = raw_prices_val.min()\n","max_val_val = raw_prices_val.max()\n","\n","val_normalized_series = (raw_prices_val - min_val_val) / (max_val_val - min_val_val)\n","\n","# Check results\n","print(val_normalized_series.head())"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":1160,"status":"ok","timestamp":1741062932242,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"2Y3DA4SjK-CW"},"outputs":[],"source":["from chronos import ChronosPipeline\n","\n","pipeline = ChronosPipeline.from_pretrained(\"amazon/chronos-t5-tiny\")\n","model = pipeline.model.model  # Extract base model\n","tokenizer = pipeline.tokenizer  # Get tokenizer"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57,"status":"ok","timestamp":1741062185543,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"2gn9n9SyKA2N","outputId":"90129ba4-c394-4ffc-962c-fd09e94787e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 49,152 || all params: 8,443,648 || trainable%: 0.5821\n"]}],"source":["### ---- first run --- ###\n","\n","from peft import LoraConfig, get_peft_model\n","\n","# Define LoRA configuration\n","lora_config = LoraConfig(\n","    r=2,  # LoRA rank\n","    lora_alpha=16,  # Scaling factor\n","    lora_dropout=0.1,\n","    target_modules=[\"SelfAttention.q\", \"SelfAttention.k\", \"SelfAttention.v\", \"SelfAttention.o\",\n","                    \"EncDecAttention.q\", \"EncDecAttention.k\", \"EncDecAttention.v\", \"EncDecAttention.o\"],\n","    bias=\"none\",\n","    task_type=\"SEQ_2_SEQ_LM\"\n",")\n","\n","# Freeze all model parameters\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Apply LoRA\n","lora_model = get_peft_model(model, lora_config)\n","lora_model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1741062934647,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"ODO3r2TfLFdW"},"outputs":[],"source":["# ### --- second --- ###\n","\n","# from peft import LoraConfig, get_peft_model\n","\n","# # Define LoRA configuration\n","# lora_config = LoraConfig(\n","#     r=4,  # LoRA rank\n","#     lora_alpha=16,  # Scaling factor\n","#     lora_dropout=0.3,\n","#     bias=\"none\",\n","#     task_type=\"SEQ_2_SEQ_LM\"\n","# )\n","\n","# # Apply LoRA\n","# lora_model = get_peft_model(model, lora_config)\n","# lora_model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1739630810227,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"TSsIKAa3pEOz","outputId":"2260d8c9-16bd-4b4c-fe8b-f0e75d3edf69"},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 663,552 || all params: 202,038,528 || trainable%: 0.3284\n"]}],"source":["# ### --- third --- ###\n","\n","# from peft import LoraConfig, get_peft_model\n","\n","# # Define LoRA configuration\n","# lora_config = LoraConfig(\n","#     r=6,  # LoRA rank\n","#     lora_alpha=32,  # Scaling factor\n","#     lora_dropout=0.1,\n","#     bias=\"none\",\n","#     task_type=\"SEQ_2_SEQ_LM\"\n","# )\n","\n","# # Apply LoRA\n","# lora_model = get_peft_model(model, lora_config)\n","# lora_model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":1193,"status":"ok","timestamp":1741062947972,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"gsYCnE0DLjDB"},"outputs":[],"source":["pipeline = ChronosPipeline.from_pretrained(\"amazon/chronos-t5-tiny\")\n","\n","# Load dataset into Chronos\n","training_data = \"./financial_data.arrow\"\n","val_data = \"./financial_val_data.arrow\""]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1056,"status":"ok","timestamp":1741062953224,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"C9lLJ3zFMtZx","outputId":"1ccd61d1-f221-434d-85f1-fb4ef799e229"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'chronos-forecasting'...\n","remote: Enumerating objects: 466, done.\u001b[K\n","remote: Counting objects: 100% (4/4), done.\u001b[K\n","remote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 466 (delta 2), reused 0 (delta 0), pack-reused 462 (from 2)\u001b[K\n","Receiving objects: 100% (466/466), 1.01 MiB | 29.51 MiB/s, done.\n","Resolving deltas: 100% (198/198), done.\n"]}],"source":["!git clone https://github.com/amazon-science/chronos-forecasting.git"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1741062954081,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"OUknor9KMwqT","outputId":"d98984f4-04e6-483a-e12e-d1c3dac73b38"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/chronos-forecasting/chronos-forecasting\n"]}],"source":["cd chronos-forecasting"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1741062992582,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"7ju9Jd06Myhb"},"outputs":[],"source":["from gluonts.dataset.arrow import ArrowWriter\n","import pandas as pd\n","import numpy as np\n","\n","def convert_financial_series_to_arrow(series, output_path=\"./financial_data.arrow\"):\n","    dataset = []\n","    for series in series_list:\n","        if not isinstance(series, pd.Series):\n","            print(f\"Skipping non-series data: {series}\")\n","            continue\n","\n","        series = pd.to_numeric(series, errors='coerce').dropna()\n","        if not np.issubdtype(series.index.dtype, np.datetime64):\n","            series.index = pd.to_datetime(series.index)\n","\n","        dataset.append({\"start\": str(series.index[0]), \"target\": series.values.tolist()})\n","\n","    ArrowWriter(compression=\"lz4\").write_to_file(dataset, path=output_path)\n","    print(f\"✅ Financial data saved to {output_path}\")"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1741063031865,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"tTwXTmuXcPr7","outputId":"64668eca-2437-40db-bbad-de72c8d887cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Financial data saved to ./financial_data.arrow\n"]}],"source":["convert_financial_series_to_arrow(train_normalized_series, output_path=\"./financial_data.arrow\")"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1741063053948,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"wP30Fo6qcZdK","outputId":"a90f3f47-c2f1-4e7a-a696-0a8cca836f4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Financial data saved to ./financial_val_data.arrow\n"]}],"source":["convert_financial_series_to_arrow(val_normalized_series, output_path=\"./financial_val_data.arrow\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1740988269700,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"hx9PSlvZNWy2","outputId":"9ce38687-f331-47c4-962b-7804acfee182"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting ./config.yaml\n"]}],"source":["# %%writefile ./config.yaml\n","# training_data_paths:\n","#   - \"./financial_data.arrow\"\n","# probability:\n","#   - 1.0\n","# model:\n","#   model_id: \"amazon/chronos-t5-tiny\"\n","#   random_init: false\n","# training:\n","#   max_steps: 10000\n","#   learning_rate: 5e-5\n","#   lr_scheduler_type: \"cosine\"\n","#   batch_size: 16\n","#   gradient_accumulation_steps: 4\n","#   warmup_ratio: 0.05\n","#   weight_decay: 0.01\n","#   fp16: true\n","#   gradient_checkpointing: true\n","#   save_steps: 5000\n","#   logging_steps: 100\n","#   eval_steps: 5000\n","#   early_stopping_patience: 3\n","# lora:\n","#   r: 2\n","#   alpha: 16\n","#   dropout: 0.1\n","#   bias: \"none\"\n","#   target_modules: [\"SelfAttention.q\", \"SelfAttention.k\", \"SelfAttention.v\", \"SelfAttention.o\",\n","#                   \"EncDecAttention.q\", \"EncDecAttention.k\", \"EncDecAttention.v\", \"EncDecAttention.o\"]"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1741063177459,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"WJ32GhbEZlUs","outputId":"c4448a55-5f29-4251-cb4a-4d646fef287a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting ./config.yaml\n"]}],"source":["%%writefile ./config.yaml\n","training_data_paths:\n","  - \"./financial_data.arrow\"\n","validation_data_paths:  # ✅ Added validation dataset\n","  - \"./financial_val_data.arrow\"\n","probability:\n","  - 1.0\n","model:\n","  model_id: \"amazon/chronos-t5-tiny\"\n","  random_init: false\n","training:\n","  max_steps: 3000  # ✅ Reduced steps to prevent overfitting\n","  learning_rate: 5e-5\n","  lr_scheduler_type: \"cosine\"\n","  batch_size: 16\n","  gradient_accumulation_steps: 4\n","  warmup_ratio: 0.05\n","  weight_decay: 0.01\n","  fp16: true\n","  gradient_checkpointing: true\n","  save_steps: 500  # ✅ Save checkpoints more frequently (500 instead of 5000)\n","  logging_steps: 100\n","  eval_steps: 500  # ✅ More frequent validation evaluation\n","  evaluation_strategy: \"steps\"  # ✅ Ensure validation runs every eval_steps\n","  save_strategy: \"epoch\"  # ✅ Save best checkpoint at the end of each epoch\n","  load_best_model_at_end: true  # ✅ Automatically use best-performing model\n","  metric_for_best_model: \"eval_loss\"  # ✅ Track validation loss\n","  greater_is_better: false  # ✅ Lower loss is better\n","  early_stopping_patience: 3  # ✅ Stop training if no improvement for 3 eval cycles\n","lora:\n","  r: 2\n","  alpha: 16\n","  dropout: 0.1\n","  bias: \"none\"\n","  target_modules: [\"SelfAttention.q\", \"SelfAttention.k\", \"SelfAttention.v\", \"SelfAttention.o\",\n","                  \"EncDecAttention.q\", \"EncDecAttention.k\", \"EncDecAttention.v\", \"EncDecAttention.o\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1739589415468,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"MPmYzW5CLe9X","outputId":"61a86433-ddd0-4ea4-b263-1c8aae368fef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing ./config.yaml\n"]}],"source":["# # --- 2nd --- #\n","\n","# %%writefile ./config.yaml\n","# training_data_paths:\n","#   - \"./financial_data.arrow\"\n","# probability:\n","#   - 1.0\n","\n","# model:\n","#   model_id: \"amazon/chronos-t5-base\"\n","#   random_init: false\n","\n","# training:\n","#   max_steps: 20000  # Reduced steps to avoid overfitting; can increase to 35000 if needed\n","#   learning_rate: 5e-5  # Lower LR to prevent catastrophic forgetting\n","#   lr_scheduler_type: \"cosine\"  # Stabilizes learning\n","#   batch_size: 8  # Smaller batch size for more frequent updates\n","#   gradient_accumulation_steps: 4  # Effective batch size = 32\n","#   warmup_ratio: 0.1\n","#   weight_decay: 0.05  # Increased to prevent overfitting\n","#   fp16: true\n","#   gradient_checkpointing: true  # Stabilizes training\n","#   save_steps: 5000  # Save every ~2.5 epochs\n","#   logging_steps: 500  # Log progress every 500 steps\n","#   eval_steps: 1333  # Evaluate every ~1 epoch\n","#   early_stopping_patience: 3  # Stop if no improvement for 3 evaluations\n","\n","# lora:\n","#   rank: 4  # Reduced to prevent over-adaptation\n","#   alpha: 16  # Keeps scaling factor same\n","#   dropout: 0.3  # Increased to avoid overfitting\n","#   bias: \"none\"\n","#   task_type: \"SEQ_2_SEQ_LM\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1739630861648,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"8X_Pm9G1myPX","outputId":"03db55c5-6c98-4c1c-eb84-cd95bbebb015"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing ./config.yaml\n"]}],"source":["# %%writefile ./config.yaml\n","# training_data_paths:\n","#   - \"./financial_data.arrow\"\n","# probability:\n","#   - 1.0\n","\n","# model:\n","#   model_id: \"amazon/chronos-t5-base\"\n","#   random_init: false\n","\n","# training:\n","#   max_steps: 31127  # Adjusted for 20 epochs\n","#   learning_rate: 3e-5  # Kept LR conservative to avoid overfitting\n","#   lr_scheduler_type: \"cosine\"\n","#   batch_size: 8\n","#   gradient_accumulation_steps: 4\n","#   warmup_ratio: 0.1\n","#   weight_decay: 0.005\n","#   fp16: true\n","#   gradient_checkpointing: true\n","#   save_steps: 5000\n","#   logging_steps: 500\n","#   eval_steps: 1500\n","#   early_stopping_patience: 3\n","\n","# lora:\n","#   rank: 6\n","#   alpha: 32  # Increased from 16 → 24 for stronger adaptation\n","#   dropout: 0.1\n","#   bias: \"none\"\n","#   task_type: \"SEQ_2_SEQ_LM\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_W8Qx2LFnau"},"outputs":[],"source":["# %%writefile ./config.yaml\n","# training_data_paths:\n","#   - \"./financial_data.arrow\"\n","# probability:\n","#   - 1.0\n","\n","# model:\n","#   model_id: \"amazon/chronos-t5-base\"\n","#   random_init: false\n","\n","# training:\n","#   max_steps: 31127  # Keep around 30k steps\n","#   learning_rate: 2e-5  # Slightly reduced learning rate for stability\n","#   lr_scheduler_type: \"cosine\"\n","#   batch_size: 8  # Keep batch size the same\n","#   gradient_accumulation_steps: 4  # Effective batch size remains 32\n","#   warmup_ratio: 0.1\n","#   weight_decay: 0.01  # Increased to regularize training\n","#   fp16: true\n","#   gradient_checkpointing: true  # Helps with memory efficiency\n","#   save_steps: 5000\n","#   logging_steps: 500\n","#   eval_steps: 1500\n","#   early_stopping_patience: 3  # Keeps early stopping in place"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1740853224607,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"8mei7YCJNewe","outputId":"11b7e2f5-429d-4a59-8046-fa4153614f80"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/chronos-forecasting/chronos-forecasting/chronos-forecasting'"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1740988311052,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"8sU0nH49Ngad","outputId":"4758a0ab-8587-4f4f-dd84-0df8f45ec3a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mci\u001b[0m/                 config.yaml      financial_data.arrow  NOTICE          \u001b[01;34mscripts\u001b[0m/\n","CITATION.cff        CONTRIBUTING.md  LICENSE               pyproject.toml  \u001b[01;34msrc\u001b[0m/\n","CODE_OF_CONDUCT.md  \u001b[01;34mfigures\u001b[0m/         \u001b[01;34mnotebooks\u001b[0m/            README.md       \u001b[01;34mtest\u001b[0m/\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1740988314908,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"OoU5S0DQwnVz","outputId":"53103641-431d-4ae9-978b-98210e16b294"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["import torch\n","print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":937833,"status":"ok","timestamp":1741064347037,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"QAFQTZ7fN4oZ","outputId":"1e63fa5c-6f3c-4551-ba25-8ea1afc1e299"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-04 04:43:33.857362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1741063413.879172   23620 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1741063413.885877   23620 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-04 04:43:37,268 - /content/chronos-forecasting/chronos-forecasting/scripts/training/train.py - INFO - Using SEED: 727628000\n","2025-03-04 04:43:37,274 - /content/chronos-forecasting/chronos-forecasting/scripts/training/train.py - INFO - Logging dir: output/run-0\n","2025-03-04 04:43:37,274 - /content/chronos-forecasting/chronos-forecasting/scripts/training/train.py - INFO - Loading and filtering 1 datasets for training: ['./financial_data.arrow']\n","2025-03-04 04:43:37,274 - /content/chronos-forecasting/chronos-forecasting/scripts/training/train.py - INFO - Mixing probabilities: [1.0]\n","2025-03-04 04:43:37,280 - /content/chronos-forecasting/chronos-forecasting/scripts/training/train.py - INFO - Initializing model\n","2025-03-04 04:43:37,280 - /content/chronos-forecasting/chronos-forecasting/scripts/training/train.py - INFO - Using pretrained initialization from amazon/chronos-t5-tiny\n","2025-03-04 04:43:38,188 - /content/chronos-forecasting/chronos-forecasting/scripts/training/train.py - INFO - Training\n","  0% 0/3000 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","{'loss': 1.7349, 'grad_norm': 0.21034200489521027, 'learning_rate': 4.8162351680370044e-05, 'epoch': 0.17}\n","{'loss': 1.7138, 'grad_norm': 0.20891210436820984, 'learning_rate': 3.9805881316624506e-05, 'epoch': 0.33}\n","{'loss': 1.697, 'grad_norm': 0.25948184728622437, 'learning_rate': 2.7064483636808313e-05, 'epoch': 0.5}\n","{'loss': 1.681, 'grad_norm': 0.26941946148872375, 'learning_rate': 1.3711666042227772e-05, 'epoch': 0.67}\n","{'loss': 1.6763, 'grad_norm': 0.315047025680542, 'learning_rate': 3.7020147790418263e-06, 'epoch': 0.83}\n","{'loss': 1.6763, 'grad_norm': 0.26527807116508484, 'learning_rate': 0.0, 'epoch': 1.0}\n","{'train_runtime': 888.1686, 'train_samples_per_second': 432.35, 'train_steps_per_second': 3.378, 'train_loss': 1.6965455729166667, 'epoch': 1.0}\n","100% 3000/3000 [14:48<00:00,  3.38it/s]\n","Training finished. Checking for checkpoints...\n","total 40\n","drwxr-xr-x 10 root root 4096 Mar  4 04:58 .\n","drwxr-xr-x  3 root root 4096 Mar  4 04:43 ..\n","drwxr-xr-x  2 root root 4096 Mar  4 04:49 checkpoint-1000\n","drwxr-xr-x  2 root root 4096 Mar  4 04:51 checkpoint-1500\n","drwxr-xr-x  2 root root 4096 Mar  4 04:53 checkpoint-2000\n","drwxr-xr-x  2 root root 4096 Mar  4 04:56 checkpoint-2500\n","drwxr-xr-x  2 root root 4096 Mar  4 04:58 checkpoint-3000\n","drwxr-xr-x  2 root root 4096 Mar  4 04:47 checkpoint-500\n","drwxr-xr-x  2 root root 4096 Mar  4 04:58 checkpoint-final\n","drwxr-xr-x  2 root root 4096 Mar  4 04:43 logs\n","  adding: output/run-0/ (stored 0%)\n","  adding: output/run-0/checkpoint-final/ (stored 0%)\n","  adding: output/run-0/checkpoint-final/generation_config.json (deflated 29%)\n","  adding: output/run-0/checkpoint-final/config.json (deflated 53%)\n","  adding: output/run-0/checkpoint-final/model.safetensors (deflated 7%)\n","  adding: output/run-0/checkpoint-final/training_info.json (deflated 57%)\n","  adding: output/run-0/logs/ (stored 0%)\n","  adding: output/run-0/logs/events.out.tfevents.1741063419.0c9d670279b3.23620.0 (deflated 61%)\n","  adding: output/run-0/checkpoint-2000/ (stored 0%)\n","  adding: output/run-0/checkpoint-2000/generation_config.json (deflated 29%)\n","  adding: output/run-0/checkpoint-2000/config.json (deflated 53%)\n","  adding: output/run-0/checkpoint-2000/trainer_state.json (deflated 62%)\n","  adding: output/run-0/checkpoint-2000/rng_state.pth (deflated 25%)\n","  adding: output/run-0/checkpoint-2000/model.safetensors (deflated 7%)\n","  adding: output/run-0/checkpoint-2000/optimizer.pt (deflated 9%)\n","  adding: output/run-0/checkpoint-2000/scheduler.pt (deflated 55%)\n","  adding: output/run-0/checkpoint-2000/training_args.bin (deflated 52%)\n","  adding: output/run-0/checkpoint-1500/ (stored 0%)\n","  adding: output/run-0/checkpoint-1500/generation_config.json (deflated 29%)\n","  adding: output/run-0/checkpoint-1500/config.json (deflated 53%)\n","  adding: output/run-0/checkpoint-1500/trainer_state.json (deflated 60%)\n","  adding: output/run-0/checkpoint-1500/rng_state.pth (deflated 25%)\n","  adding: output/run-0/checkpoint-1500/model.safetensors (deflated 7%)\n","  adding: output/run-0/checkpoint-1500/optimizer.pt (deflated 9%)\n","  adding: output/run-0/checkpoint-1500/scheduler.pt (deflated 56%)\n","  adding: output/run-0/checkpoint-1500/training_args.bin (deflated 52%)\n","  adding: output/run-0/checkpoint-3000/ (stored 0%)\n","  adding: output/run-0/checkpoint-3000/generation_config.json (deflated 29%)\n","  adding: output/run-0/checkpoint-3000/config.json (deflated 53%)\n","  adding: output/run-0/checkpoint-3000/trainer_state.json (deflated 65%)\n","  adding: output/run-0/checkpoint-3000/rng_state.pth (deflated 25%)\n","  adding: output/run-0/checkpoint-3000/model.safetensors (deflated 7%)\n","  adding: output/run-0/checkpoint-3000/optimizer.pt (deflated 9%)\n","  adding: output/run-0/checkpoint-3000/scheduler.pt (deflated 56%)\n","  adding: output/run-0/checkpoint-3000/training_args.bin (deflated 52%)\n","  adding: output/run-0/checkpoint-2500/ (stored 0%)\n","  adding: output/run-0/checkpoint-2500/generation_config.json (deflated 29%)\n","  adding: output/run-0/checkpoint-2500/config.json (deflated 53%)\n","  adding: output/run-0/checkpoint-2500/trainer_state.json (deflated 64%)\n","  adding: output/run-0/checkpoint-2500/rng_state.pth (deflated 25%)\n","  adding: output/run-0/checkpoint-2500/model.safetensors (deflated 7%)\n","  adding: output/run-0/checkpoint-2500/optimizer.pt (deflated 9%)\n","  adding: output/run-0/checkpoint-2500/scheduler.pt (deflated 55%)\n","  adding: output/run-0/checkpoint-2500/training_args.bin (deflated 52%)\n","  adding: output/run-0/checkpoint-1000/ (stored 0%)\n","  adding: output/run-0/checkpoint-1000/generation_config.json (deflated 29%)\n","  adding: output/run-0/checkpoint-1000/config.json (deflated 53%)\n","  adding: output/run-0/checkpoint-1000/trainer_state.json (deflated 58%)\n","  adding: output/run-0/checkpoint-1000/rng_state.pth (deflated 25%)\n","  adding: output/run-0/checkpoint-1000/model.safetensors (deflated 7%)\n","  adding: output/run-0/checkpoint-1000/optimizer.pt (deflated 9%)\n","  adding: output/run-0/checkpoint-1000/scheduler.pt (deflated 56%)\n","  adding: output/run-0/checkpoint-1000/training_args.bin (deflated 52%)\n","  adding: output/run-0/checkpoint-500/ (stored 0%)\n","  adding: output/run-0/checkpoint-500/generation_config.json (deflated 29%)\n","  adding: output/run-0/checkpoint-500/config.json (deflated 53%)\n","  adding: output/run-0/checkpoint-500/trainer_state.json (deflated 55%)\n","  adding: output/run-0/checkpoint-500/rng_state.pth (deflated 25%)\n","  adding: output/run-0/checkpoint-500/model.safetensors (deflated 7%)\n","  adding: output/run-0/checkpoint-500/optimizer.pt (deflated 9%)\n","  adding: output/run-0/checkpoint-500/scheduler.pt (deflated 55%)\n","  adding: output/run-0/checkpoint-500/training_args.bin (deflated 52%)\n"]}],"source":["# Train the model - explicitly specifying the same parameters as in the config file\n","!CUDA_VISIBLE_DEVICES=0 python scripts/training/train.py \\\n","    --config ./config.yaml \\\n","    --model-id amazon/chronos-t5-tiny \\\n","    --no-random-init \\\n","    --max-steps 3000 \\\n","    --learning-rate 5e-5 \\\n","    --lr-scheduler-type cosine \\\n","    --gradient-accumulation-steps 4 \\\n","    --warmup-ratio 0.05 \\\n","    --save-steps 500 \\\n","\n","# Echo training completion\n","!echo \"Training finished. Checking for checkpoints...\"\n","\n","# List the output directory to confirm checkpoints were created\n","!ls -la output/run-0/\n","\n","# Zip the fine-tuned model (run-0) and rename it\n","!zip -r fine_tuned_chronos_sp500_rk2_3000.zip output/run-0/\n","\n","# Save the zip file to Google Drive\n","!cp fine_tuned_chronos_sp500_rk2_3000.zip /content/drive/MyDrive/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1739574931533,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"EtYl2IW9vuJa","outputId":"4a839e0a-ec0e-4769-da9f-e78c820ced9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mcheckpoint-27330\u001b[0m/  \u001b[01;34mcheckpoint-final\u001b[0m/  \u001b[01;34mlogs\u001b[0m/\n"]}],"source":["ls output/run-0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9f8NNOpxOCQ"},"outputs":[],"source":["!mkdir -p fine_tuned_chronos\n","!cp -r output/run-0/* fine_tuned_chronos/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":671,"status":"ok","timestamp":1739575559486,"user":{"displayName":"Anthony Bolton","userId":"09458477616352491057"},"user_tz":0},"id":"X5BbYq04yHjK","outputId":"9a0454e4-9dc1-4edc-db95-1e40563bb906"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mci\u001b[0m/                 config.yaml      financial_data.arrow  NOTICE          README.md  \u001b[01;34mtest\u001b[0m/\n","CITATION.cff        CONTRIBUTING.md  \u001b[01;34mfine_tuned_chronos\u001b[0m/   \u001b[01;34moutput\u001b[0m/         \u001b[01;34mscripts\u001b[0m/\n","CODE_OF_CONDUCT.md  \u001b[01;34mfigures\u001b[0m/         LICENSE               pyproject.toml  \u001b[01;34msrc\u001b[0m/\n"]}],"source":["ls"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPZqoZu4KzGTvflX1AmCAV4","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
