{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7cf5fa7d154cff859dafcec47c1f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dd2de5293a42ebb019c4dad69b6c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/404k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = InformerForPrediction.from_pretrained(\n",
    "    \"huggingface/informer-tourism-monthly\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "Context length: 24\n",
      "Prediction length: 24\n",
      "Lags sequence: [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 23, 24, 25, 35, 36, 37]\n",
      "Number of time features: 2\n",
      "\n",
      "Required dimensions:\n",
      "Context window: 61 (includes max lag: 37 + context length: 24)\n",
      "Prediction window: 24\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (24x20 and 22x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 163\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Generate full period forecast\u001b[39;00m\n\u001b[1;32m    162\u001b[0m context \u001b[38;5;241m=\u001b[39m sp500_d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39mCONTEXT_WINDOW:]\n\u001b[0;32m--> 163\u001b[0m low, median, high \u001b[38;5;241m=\u001b[39m generate_forecast(context)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Calculate and print metrics for full period\u001b[39;00m\n\u001b[1;32m    166\u001b[0m actual_prices \u001b[38;5;241m=\u001b[39m sp500_d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39mPREDICTION_WINDOW:]\n",
      "Cell \u001b[0;32mIn[2], line 71\u001b[0m, in \u001b[0;36mgenerate_forecast\u001b[0;34m(context_data)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m future_time_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m prediction_length, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in future_time_features length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m past_time_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m num_features, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in time feature dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 71\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     72\u001b[0m     past_values\u001b[38;5;241m=\u001b[39mpast_values,\n\u001b[1;32m     73\u001b[0m     past_time_features\u001b[38;5;241m=\u001b[39mpast_time_features,\n\u001b[1;32m     74\u001b[0m     future_time_features\u001b[38;5;241m=\u001b[39mfuture_time_features,\n\u001b[1;32m     75\u001b[0m     past_observed_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     76\u001b[0m     static_categorical_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m     static_real_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     80\u001b[0m forecast_samples \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msequences\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     81\u001b[0m forecast_samples \u001b[38;5;241m=\u001b[39m forecast_samples \u001b[38;5;241m*\u001b[39m context_std \u001b[38;5;241m+\u001b[39m context_mean\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1979\u001b[0m, in \u001b[0;36mInformerForPrediction.generate\u001b[0;34m(self, past_values, past_time_features, future_time_features, past_observed_mask, static_categorical_features, static_real_features, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m   1882\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1890\u001b[0m     output_hidden_states: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1891\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleTSPredictionOutput:\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1893\u001b[0m \u001b[38;5;124;03m    Greedily generate sequences of sample predictions from a model with a probability distribution head.\u001b[39;00m\n\u001b[1;32m   1894\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;124;03m        multivariate predictions.\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1979\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[1;32m   1980\u001b[0m         static_categorical_features\u001b[38;5;241m=\u001b[39mstatic_categorical_features,\n\u001b[1;32m   1981\u001b[0m         static_real_features\u001b[38;5;241m=\u001b[39mstatic_real_features,\n\u001b[1;32m   1982\u001b[0m         past_time_features\u001b[38;5;241m=\u001b[39mpast_time_features,\n\u001b[1;32m   1983\u001b[0m         past_values\u001b[38;5;241m=\u001b[39mpast_values,\n\u001b[1;32m   1984\u001b[0m         past_observed_mask\u001b[38;5;241m=\u001b[39mpast_observed_mask,\n\u001b[1;32m   1985\u001b[0m         future_time_features\u001b[38;5;241m=\u001b[39mfuture_time_features,\n\u001b[1;32m   1986\u001b[0m         future_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1987\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1988\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1989\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1990\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1991\u001b[0m     )\n\u001b[1;32m   1993\u001b[0m     decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_decoder()\n\u001b[1;32m   1994\u001b[0m     enc_last_hidden \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mencoder_last_hidden_state\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1822\u001b[0m, in \u001b[0;36mInformerForPrediction.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, future_observed_mask, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1820\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1822\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1823\u001b[0m     past_values\u001b[38;5;241m=\u001b[39mpast_values,\n\u001b[1;32m   1824\u001b[0m     past_time_features\u001b[38;5;241m=\u001b[39mpast_time_features,\n\u001b[1;32m   1825\u001b[0m     past_observed_mask\u001b[38;5;241m=\u001b[39mpast_observed_mask,\n\u001b[1;32m   1826\u001b[0m     static_categorical_features\u001b[38;5;241m=\u001b[39mstatic_categorical_features,\n\u001b[1;32m   1827\u001b[0m     static_real_features\u001b[38;5;241m=\u001b[39mstatic_real_features,\n\u001b[1;32m   1828\u001b[0m     future_values\u001b[38;5;241m=\u001b[39mfuture_values,\n\u001b[1;32m   1829\u001b[0m     future_time_features\u001b[38;5;241m=\u001b[39mfuture_time_features,\n\u001b[1;32m   1830\u001b[0m     decoder_attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[1;32m   1831\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1832\u001b[0m     decoder_head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[1;32m   1833\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[1;32m   1834\u001b[0m     encoder_outputs\u001b[38;5;241m=\u001b[39mencoder_outputs,\n\u001b[1;32m   1835\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1836\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1837\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1838\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1839\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1840\u001b[0m )\n\u001b[1;32m   1842\u001b[0m prediction_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1654\u001b[0m, in \u001b[0;36mInformerModel.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     enc_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m-> 1654\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1655\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39menc_input,\n\u001b[1;32m   1656\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1657\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1658\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1659\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1660\u001b[0m     )\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1149\u001b[0m, in \u001b[0;36mInformerEncoder.forward\u001b[0;34m(self, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1144\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1145\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1146\u001b[0m )\n\u001b[1;32m   1147\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1149\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_embedding(inputs_embeds)\n\u001b[1;32m   1150\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_positions(inputs_embeds\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   1152\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm_embedding(hidden_states \u001b[38;5;241m+\u001b[39m embed_pos)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:275\u001b[0m, in \u001b[0;36mInformerValueEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_projection(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (24x20 and 22x32)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import InformerConfig, InformerForPrediction\n",
    "\n",
    "from data.snp500 import snp500_daily\n",
    "from utils.metrics import metric\n",
    "\n",
    "# Initialize pretrained Informer model\n",
    "model = InformerForPrediction.from_pretrained(\"huggingface/informer-tourism-monthly\")\n",
    "\n",
    "# Print model configuration details\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"Context length: {model.config.context_length}\")\n",
    "print(f\"Prediction length: {model.config.prediction_length}\")\n",
    "print(f\"Lags sequence: {model.config.lags_sequence}\")\n",
    "print(f\"Number of time features: {model.config.num_time_features}\")\n",
    "\n",
    "# Calculate required context window based on model's config\n",
    "max_lag = max(model.config.lags_sequence) if model.config.lags_sequence else 0\n",
    "CONTEXT_WINDOW = max_lag + model.config.context_length\n",
    "PREDICTION_WINDOW = model.config.prediction_length\n",
    "\n",
    "print(f\"\\nRequired dimensions:\")\n",
    "print(f\"Context window: {CONTEXT_WINDOW} (includes max lag: {max_lag} + context length: {model.config.context_length})\")\n",
    "print(f\"Prediction window: {PREDICTION_WINDOW}\")\n",
    "\n",
    "# Prepare the data - using raw Close prices\n",
    "sp500_d = snp500_daily.reset_index()[[\"Date\", \"Close\"]]\n",
    "\n",
    "def generate_forecast(context_data):\n",
    "    \"\"\"Generate and process forecast using Informer\"\"\"\n",
    "    context_length = model.config.context_length\n",
    "    prediction_length = model.config.prediction_length\n",
    "    num_features = model.config.num_time_features\n",
    "    input_size = model.config.input_size\n",
    "    max_lag = max(model.config.lags_sequence)\n",
    "    required_length = context_length + max_lag\n",
    "\n",
    "    context = np.asarray(context_data).flatten()\n",
    "    if len(context) < required_length:\n",
    "        num_repeats = (required_length - len(context)) // len(context) + 1\n",
    "        padded_data = np.tile(context, num_repeats)\n",
    "        context = padded_data[-required_length:]\n",
    "    else:\n",
    "        context = context[-required_length:]\n",
    "\n",
    "    context_mean = np.mean(context)\n",
    "    context_std = np.std(context)\n",
    "    context_scaled = (context - context_mean) / context_std\n",
    "\n",
    "    past_values = torch.tensor(context_scaled).float().unsqueeze(0)\n",
    "\n",
    "    timesteps = np.arange(required_length)\n",
    "    time_feat1 = (timesteps % 365) / 365.0\n",
    "    time_feat2 = np.cos(2 * np.pi * timesteps / 365.0)\n",
    "    time_features = np.stack([time_feat1, time_feat2], axis=-1)\n",
    "    past_time_features = torch.tensor(time_features).float().unsqueeze(0)\n",
    "\n",
    "    future_timesteps = np.arange(prediction_length) + len(timesteps)\n",
    "    future_feat1 = (future_timesteps % 365) / 365.0\n",
    "    future_feat2 = np.cos(2 * np.pi * future_timesteps / 365.0)\n",
    "    future_time_features = np.stack([future_feat1, future_feat2], axis=-1)\n",
    "    future_time_features = torch.tensor(future_time_features).float().unsqueeze(0)\n",
    "\n",
    "    # Verify dimensions\n",
    "    if past_time_features.shape[-1] != num_features:\n",
    "        raise ValueError(f\"Mismatch in past time features: expected {num_features}, got {past_time_features.shape[-1]}\")\n",
    "    if future_time_features.shape[-1] != num_features:\n",
    "        raise ValueError(f\"Mismatch in future time features: expected {num_features}, got {future_time_features.shape[-1]}\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        past_values=past_values,\n",
    "        past_time_features=past_time_features,\n",
    "        future_time_features=future_time_features,\n",
    "        past_observed_mask=None,\n",
    "        static_categorical_features=None,\n",
    "        static_real_features=None,\n",
    "    )\n",
    "\n",
    "    forecast_samples = outputs.sequences.squeeze().detach().numpy()\n",
    "    forecast_samples = forecast_samples * context_std + context_mean\n",
    "\n",
    "    low, median, high = np.quantile(forecast_samples, [0.1, 0.5, 0.9], axis=0)\n",
    "    return low, median, high\n",
    "\n",
    "def calculate_metrics(actual, predicted, insample=None):\n",
    "    actual = np.array(actual).flatten()\n",
    "    predicted = np.array(predicted).flatten()\n",
    "\n",
    "    mae, mse, rmse, mape, mspe = metric(predicted, actual)\n",
    "\n",
    "    smape = 200 * np.mean(\n",
    "        np.abs(predicted - actual) / (np.abs(predicted) + np.abs(actual))\n",
    "    )\n",
    "\n",
    "    if insample is not None:\n",
    "        naive_forecast = insample[:-1]\n",
    "        naive_target = insample[1:]\n",
    "        naive_mae = np.mean(np.abs(naive_target - naive_forecast))\n",
    "        mase = mae / naive_mae if naive_mae != 0 else np.nan\n",
    "    else:\n",
    "        mase = np.nan\n",
    "\n",
    "    metrics = {\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE\": mape * 100,\n",
    "        \"SMAPE\": smape,\n",
    "        \"MASE\": mase if not np.isnan(mase) else None,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def plot_forecast(data, context_window, prediction_window, median_forecast, low_forecast, high_forecast, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    last_context_point = data[\"Close\"].iloc[-prediction_window - 1]\n",
    "\n",
    "    median_forecast = np.insert(median_forecast, 0, last_context_point)\n",
    "    low_forecast = np.insert(low_forecast, 0, last_context_point)\n",
    "    high_forecast = np.insert(high_forecast, 0, last_context_point)\n",
    "\n",
    "    forecast_dates = pd.concat(\n",
    "        [\n",
    "            data[\"Date\"].iloc[-(prediction_window + 1) : -prediction_window],\n",
    "            data[\"Date\"].iloc[-prediction_window:],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    actual_prices = data[\"Close\"].iloc[-prediction_window:].values\n",
    "    actual_prices = np.insert(actual_prices, 0, last_context_point)\n",
    "\n",
    "    plt.plot(\n",
    "        data[\"Date\"].iloc[-(context_window + prediction_window) : -prediction_window],\n",
    "        data[\"Close\"].iloc[-(context_window + prediction_window) : -prediction_window],\n",
    "        color=\"royalblue\",\n",
    "        label=\"Historical Data (Context)\",\n",
    "    )\n",
    "\n",
    "    plt.plot(forecast_dates, actual_prices, color=\"green\", label=\"Actual Prices\")\n",
    "    plt.plot(forecast_dates, median_forecast, color=\"tomato\", label=\"Median Forecast\")\n",
    "    plt.fill_between(\n",
    "        forecast_dates,\n",
    "        low_forecast,\n",
    "        high_forecast,\n",
    "        color=\"tomato\",\n",
    "        alpha=0.3,\n",
    "        label=\"80% Prediction Interval\",\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"S&P 500 Price\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Generate full period forecast\n",
    "context = sp500_d[\"Close\"].values[-CONTEXT_WINDOW:]\n",
    "low, median, high = generate_forecast(context)\n",
    "\n",
    "# Calculate and print metrics for full period\n",
    "actual_prices = sp500_d[\"Close\"].values[-PREDICTION_WINDOW:]\n",
    "insample_data = sp500_d[\"Close\"].values[\n",
    "    -CONTEXT_WINDOW - PREDICTION_WINDOW : -PREDICTION_WINDOW\n",
    "]\n",
    "metrics = calculate_metrics(actual_prices, median, insample=insample_data)\n",
    "\n",
    "print(\"\\nFull Period Metrics:\")\n",
    "for metric_name, value in metrics.items():\n",
    "    if value is not None:\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric_name}: N/A\")\n",
    "\n",
    "# Plot full period forecast\n",
    "plot_forecast(\n",
    "    sp500_d,\n",
    "    CONTEXT_WINDOW,\n",
    "    PREDICTION_WINDOW,\n",
    "    median,\n",
    "    low,\n",
    "    high,\n",
    "    \"S&P 500 Price Prediction with Informer\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
